{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from typing import List, Dict, Union, Optional, Any, Tuple\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import conv, Sequential, summary\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import stype, NAStrategy\n",
    "from torch_frame.nn import encoder\n",
    "from torch_frame.nn import TabTransformerConv\n",
    "from torch_frame.data import StatType\n",
    "\n",
    "\n",
    "from db_transformer.nn import (\n",
    "    BlueprintModel,\n",
    "    EmbeddingTranscoder,\n",
    "    SelfAttention,\n",
    "    CrossAttentionConv,\n",
    "    NodeApplied,\n",
    ")\n",
    "from db_transformer.data.ctu_dataset import CTUDataset\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if False and torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model: BlueprintModel, target_table: str, lr: float) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.target_table = target_table\n",
    "        self.lr = lr\n",
    "        self.loss_module = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        out = self.model(data.collect(\"tf\"), data.collect(\"edge_index\", allow_empty=True))\n",
    "\n",
    "        target = data[self.target_table].y\n",
    "        loss = self.loss_module(out, target)\n",
    "        acc = (out.argmax(dim=-1) == target).type(torch.float).mean()\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "        self.log(\"train_loss\", loss, batch_size=batch_size, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, batch_size=batch_size, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        _, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "\n",
    "        self.log(\"val_acc\", acc, batch_size=batch_size, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        _, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "\n",
    "        self.log(\"test_acc\", acc, batch_size=batch_size, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CTUDataset(\"medical\", data_dir=\"../datasets\", force_remake=True)\n",
    "\n",
    "data = dataset.build_hetero_data(device, force_rematerilize=True)\n",
    "\n",
    "n_total = data[dataset.defaults.target_table].y.shape[0]\n",
    "data = T.RandomNodeSplit(split=\"train_rest\", num_val=int(0.30 * n_total), num_test=0)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "num_neighbors = {edge_type: [30] * 5 for edge_type in data.collect(\"edge_index\").keys()}\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=10000,\n",
    "    input_nodes=(target[0], data[target[0]].train_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=1000,\n",
    "    input_nodes=(target[0], data[target[0]].val_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "embed_dim = 64\n",
    "\n",
    "model = BlueprintModel(\n",
    "    target=target,\n",
    "    embed_dim=embed_dim,\n",
    "    col_stats_per_table=data.collect(\"col_stats\"),\n",
    "    col_names_dict_per_table={k: tf.col_names_dict for k, tf in data.collect(\"tf\").items()},\n",
    "    edge_types=list(data.collect(\"edge_index\").keys()),\n",
    "    stype_encoder_dict={\n",
    "        stype.categorical: encoder.EmbeddingEncoder(\n",
    "            na_strategy=NAStrategy.MOST_FREQUENT,\n",
    "        ),\n",
    "        stype.numerical: encoder.LinearEncoder(\n",
    "            na_strategy=NAStrategy.MEAN,\n",
    "        ),\n",
    "        stype.embedding: EmbeddingTranscoder(in_channels=300),\n",
    "    },\n",
    "    positional_encoding=True,\n",
    "    num_gnn_layers=3,\n",
    "    table_transform=SelfAttention(embed_dim, 16),\n",
    "    table_transform_unique=True,\n",
    "    # table_transform=lambda i, node, cols: ExcelFormerConv(embed_dim, len(cols), 1),\n",
    "    table_combination=CrossAttentionConv(embed_dim, 4),\n",
    "    table_combination_unique=True,\n",
    "    # table_combination=conv.TransformerConv(embed_dim, embed_dim, heads=4, dropout=0.1, root_weight=False),\n",
    "    decoder_aggregation=lambda x: torch.reshape(x, (-1, math.prod(x.shape[1:]))),\n",
    "    decoder=lambda cols: torch.nn.Sequential(\n",
    "        torch.nn.Linear(\n",
    "            embed_dim * len(cols),\n",
    "            len(data[target[0]].col_stats[target[1]][StatType.COUNT][0]),\n",
    "        ),\n",
    "    ),\n",
    "    output_activation=torch.nn.Softmax(dim=-1),\n",
    "    positional_encoding_dropout=0.0,\n",
    "    table_transform_dropout=0.1,\n",
    "    table_combination_dropout=0.1,\n",
    "    table_transform_residual=False,\n",
    "    table_combination_residual=False,\n",
    "    table_transform_norm=False,\n",
    "    table_combination_norm=False,\n",
    ").to(device)\n",
    "print(summary(model, data.collect(\"tf\"), data.collect(\"edge_index\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = LightningModel(model, dataset.defaults.target_table, lr=0.0001).to(device)\n",
    "trainer = L.Trainer(\n",
    "    accelerator=device.type,\n",
    "    devices=1,\n",
    "    deterministic=False,\n",
    "    max_epochs=100,\n",
    "    max_steps=-1,\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-db-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
