{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from typing import List, Dict, Union, Optional, Any, Tuple, Literal\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import conv, Sequential, summary\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import stype, NAStrategy\n",
    "from torch_frame.nn import encoder\n",
    "\n",
    "from torch_frame.nn import TabTransformerConv\n",
    "from torch_frame.data import StatType\n",
    "\n",
    "\n",
    "from db_transformer.nn import (\n",
    "    BlueprintModel,\n",
    "    EmbeddingTranscoder,\n",
    "    SelfAttention,\n",
    "    CrossAttentionConv,\n",
    "    NodeApplied,\n",
    ")\n",
    "from db_transformer.nn.lightning import LightningWrapper\n",
    "from db_transformer.nn.lightning.callbacks import BestMetricsLoggerCallback\n",
    "\n",
    "from db_transformer.data.ctu_dataset import CTUDataset, CTU_REPOSITORY_DEFAULTS, TaskType\n",
    "\n",
    "from experiments.blueprint_instances import create_blueprint_model\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/info.csv\")\n",
    "# df = df.sort_values(\"n_target_tuples\", ascending=False, inplace=False)\n",
    "df[\"size\"] = \"\"\n",
    "df.loc[df[\"n_target_tuples\"].between(0, 1000), \"size\"] = \"0-1000\"\n",
    "df.loc[df[\"n_target_tuples\"].between(1001, 10000), \"size\"] = \"1001-10000\"\n",
    "df.loc[df[\"n_target_tuples\"].between(10001, 100000), \"size\"] = \"10001-100000\"\n",
    "df.loc[df[\"n_target_tuples\"].between(100001, 1000000), \"size\"] = \"100001-1000000\"\n",
    "df.loc[df[\"n_target_tuples\"].between(1000001, 10000000), \"size\"] = \"1000001-10000000\"\n",
    "\n",
    "\n",
    "print(\n",
    "    \"tiny:\",\n",
    "    df.loc[df[\"size\"] == \"0-1000\"].loc[df[\"task\"] == \"categorical\"][\"dataset\"].values,\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"small:\",\n",
    "    df.loc[df[\"size\"] == \"1001-10000\"].loc[df[\"task\"] == \"categorical\"][\"dataset\"].values,\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"medium:\",\n",
    "    df.loc[df[\"size\"] == \"10001-100000\"].loc[df[\"task\"] == \"categorical\"][\"dataset\"].values,\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"big:\",\n",
    "    df.loc[df[\"size\"] == \"100001-1000000\"]\n",
    "    .loc[df[\"task\"] == \"categorical\"][\"dataset\"]\n",
    "    .values,\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"giant:\",\n",
    "    df.loc[df[\"size\"] == \"1000001-10000000\"]\n",
    "    .loc[df[\"task\"] == \"categorical\"][\"dataset\"]\n",
    "    .values,\n",
    "    \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CTUDataset(\"PremierLeague\", data_dir=\"../datasets\", force_remake=False)\n",
    "\n",
    "data = dataset.build_hetero_data(force_rematerilize=False, no_text_emebedding=False)\n",
    "\n",
    "n_total = data[dataset.defaults.target_table].y.shape[0]\n",
    "\n",
    "data = T.RandomNodeSplit(split=\"train_rest\", num_val=int(0.30 * n_total), num_test=0)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "num_neighbors = {\n",
    "    edge_type: [30] * 5 for edge_type in data.collect(\"edge_index\", allow_empty=True).keys()\n",
    "}\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=512,\n",
    "    input_nodes=(target[0], data[target[0]].train_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=512,\n",
    "    input_nodes=(target[0], data[target[0]].val_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample: HeteroData = next(iter(train_loader))\n",
    "\n",
    "y: torch.Tensor = sample[target[0]].y\n",
    "print(y.unique(return_counts=True))\n",
    "# print(y.min(), y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = list(data.collect(\"edge_index\", allow_empty=True).keys())\n",
    "\n",
    "model = create_blueprint_model(\n",
    "    \"transformer\",\n",
    "    dataset.defaults,\n",
    "    {node: tf.col_names_dict for node, tf in data.collect(\"tf\").items() if tf.num_rows > 0},\n",
    "    edge_types,\n",
    "    data.collect(\"col_stats\"),\n",
    "    dict(\n",
    "        embed_dim=64,\n",
    "        encoder=\"with_time\",\n",
    "        gnn_layers=2,\n",
    "        mlp_dims=[64, 64],\n",
    "        num_heads=4,\n",
    "        residual=True,\n",
    "        batch_norm=True,\n",
    "        dropout=0,\n",
    "    ),\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(\n",
    "    summary(\n",
    "        model.cpu(),\n",
    "        sample.collect(\"tf\"),\n",
    "        sample.collect(\"edge_index\", allow_empty=True),\n",
    "        max_depth=10,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_regression = dataset.defaults.task == TaskType.REGRESSION\n",
    "\n",
    "lightning_model = LightningWrapper(\n",
    "    model, dataset.defaults.target_table, lr=0.0001, task_type=dataset.defaults.task\n",
    ").to(device)\n",
    "\n",
    "metric = \"mae\" if is_regression else \"accuracy\"\n",
    "cmp = \"min\" if is_regression else \"max\"\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=device.type,\n",
    "    devices=1,\n",
    "    deterministic=False,\n",
    "    max_epochs=1000,\n",
    "    max_steps=-1,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    "    callbacks=[\n",
    "        BestMetricsLoggerCallback(\n",
    "            monitor=f\"val_{metric}\",\n",
    "            cmp=cmp,\n",
    "            metrics=[\n",
    "                # \"train_loss\",\n",
    "                # \"val_loss\",\n",
    "                # \"test_loss\",\n",
    "                # f\"train_{metric}\",\n",
    "                f\"val_{metric}\",\n",
    "                f\"test_{metric}\",\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-db-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
