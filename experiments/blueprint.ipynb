{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from typing import List, Dict, Union, Optional, Any, Tuple, Literal\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import conv, Sequential, summary\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame import stype, NAStrategy\n",
    "from torch_frame.nn import encoder\n",
    "from torch_frame.nn import TabTransformerConv\n",
    "from torch_frame.data import StatType\n",
    "\n",
    "\n",
    "from db_transformer.nn import (\n",
    "    BlueprintModel,\n",
    "    EmbeddingTranscoder,\n",
    "    SelfAttention,\n",
    "    CrossAttentionConv,\n",
    "    NodeApplied,\n",
    ")\n",
    "from db_transformer.nn.lightning import LightningWrapper\n",
    "from db_transformer.nn.lightning.callbacks import BestMetricsLoggerCallback\n",
    "\n",
    "from db_transformer.data.ctu_dataset import CTUDataset, CTU_REPOSITORY_DEFAULTS\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if False and torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CTUDataset(\"Chess\", data_dir=\"../datasets\", force_remake=False)\n",
    "\n",
    "data = dataset.build_hetero_data(device, force_rematerilize=False)\n",
    "\n",
    "n_total = data[dataset.defaults.target_table].y.shape[0]\n",
    "data = T.RandomNodeSplit(split=\"train_rest\", num_val=int(0.30 * n_total), num_test=0)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "num_neighbors = {edge_type: [30] * 5 for edge_type in data.collect(\"edge_index\").keys()}\n",
    "\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=10000,\n",
    "    input_nodes=(target[0], data[target[0]].train_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    batch_size=1000,\n",
    "    input_nodes=(target[0], data[target[0]].val_mask),\n",
    "    subgraph_type=\"bidirectional\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "embed_dim = 64\n",
    "num_layers = 3\n",
    "\n",
    "df_dict = {k: table.df for k, table in dataset.db.table_dict.items()}\n",
    "\n",
    "\n",
    "def squeeze_dict(x: torch.Tensor):\n",
    "    return x.view(*x.shape[:-2], -1)\n",
    "\n",
    "\n",
    "model = BlueprintModel(\n",
    "    target=target,\n",
    "    embed_dim=embed_dim,\n",
    "    col_stats_per_table=data.collect(\"col_stats\"),\n",
    "    col_names_dict_per_table={k: tf.col_names_dict for k, tf in data.collect(\"tf\").items()},\n",
    "    edge_types=list(data.collect(\"edge_index\").keys()),\n",
    "    stype_encoder_dict={\n",
    "        stype.categorical: encoder.EmbeddingEncoder(\n",
    "            na_strategy=NAStrategy.MOST_FREQUENT,\n",
    "        ),\n",
    "        stype.numerical: encoder.LinearEncoder(\n",
    "            na_strategy=NAStrategy.MEAN,\n",
    "        ),\n",
    "    },\n",
    "    positional_encoding=False,\n",
    "    per_column_embedding=False,\n",
    "    num_gnn_layers=num_layers,\n",
    "    table_transform=lambda i, node, cols: (\n",
    "        torch.nn.Identity() if i == 0 else torch.nn.ReLU()\n",
    "    ),\n",
    "    table_transform_unique=True,\n",
    "    table_combination=lambda i, edge, cols: conv.SAGEConv(\n",
    "        (\n",
    "            len(cols[0]) * int(embed_dim / 2**i),\n",
    "            len(cols[1]) * int(embed_dim / 2**i),\n",
    "        ),\n",
    "        len(cols[1]) * int(embed_dim / 2 ** (i + 1)),\n",
    "        aggr=\"sum\",\n",
    "    ),\n",
    "    table_combination_unique=True,\n",
    "    decoder_aggregation=torch.nn.Identity(),\n",
    "    decoder=lambda cols: torch.nn.Sequential(\n",
    "        torch.nn.Linear(\n",
    "            len(cols) * int(embed_dim / 2**num_layers),\n",
    "            len(data[target[0]].col_stats[target[1]][StatType.COUNT][0]),\n",
    "        ),\n",
    "    ),\n",
    "    output_activation=torch.nn.Softmax(dim=-1),\n",
    "    positional_encoding_dropout=0.0,\n",
    "    table_transform_dropout=0.0,\n",
    "    table_combination_dropout=0.0,\n",
    "    table_transform_residual=False,\n",
    "    table_combination_residual=False,\n",
    "    table_transform_norm=False,\n",
    "    table_combination_norm=False,\n",
    ").to(device)\n",
    "print(summary(model, data.collect(\"tf\"), data.collect(\"edge_index\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = LightningWrapper(model, dataset.defaults.target_table, lr=0.0001).to(\n",
    "    device\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    accelerator=device.type,\n",
    "    devices=1,\n",
    "    deterministic=False,\n",
    "    # callbacks=[BestMetricsLoggerCallback()],\n",
    "    max_epochs=1000,\n",
    "    max_steps=-1,\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-db-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
