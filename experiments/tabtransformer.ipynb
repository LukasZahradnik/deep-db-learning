{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "\n",
    "import lightning as L\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import conv\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.typing import EdgeType, NodeType\n",
    "\n",
    "import torch_frame\n",
    "from torch_frame.data import StatType\n",
    "\n",
    "from db_transformer.nn.embedder import TabTransformerEmbedder, TromptEmbedder, FTTransformerEmbedder\n",
    "from db_transformer.data.ctu_dataset import CTUDataset\n",
    "\n",
    "device = torch.device('cuda' if False and torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_table: str,\n",
    "        table_col_stats: Dict[NodeType, Dict[str, Dict[StatType, Any]]],\n",
    "        table_col_names_dict: Dict[torch_frame.stype, List[str]],\n",
    "        edge_types: List[EdgeType],\n",
    "        embed_dim: int,\n",
    "        out_dim: int,\n",
    "        num_embedder_layers: int = 1,\n",
    "        num_embedder_heads: int = 1,\n",
    "        num_transformer_heads: int = 1,\n",
    "        embedder_attn_dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.target_table = target_table\n",
    "\n",
    "        self.embedder = TabTransformerEmbedder(\n",
    "            table_col_stats=table_col_stats,\n",
    "            table_col_names_dict=table_col_names_dict,\n",
    "            embed_dim=embed_dim,\n",
    "            num_layers=num_embedder_layers,\n",
    "            num_heads=num_embedder_heads,\n",
    "            attn_dropout=embedder_attn_dropout,\n",
    "        )\n",
    "\n",
    "        convs = {\n",
    "            edge_type: conv.TransformerConv(\n",
    "                in_channels=embed_dim, out_channels=embed_dim, heads=num_transformer_heads\n",
    "            )\n",
    "            for edge_type in edge_types\n",
    "        }\n",
    "        self.conv = conv.HeteroConv(convs) if len(edge_types) > 0 else lambda x, edge: x\n",
    "\n",
    "        self.out_lin = torch.nn.Linear(embed_dim * num_transformer_heads, out_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        tf_dict: Dict[str, torch_frame.TensorFrame],\n",
    "        edge_dict: Dict[str, torch.Tensor],\n",
    "    ):\n",
    "        x_dict = self.embedder(tf_dict)\n",
    "        x_dict = self.conv(x_dict, edge_dict)\n",
    "\n",
    "        x_target = x_dict[self.target_table]\n",
    "\n",
    "        x_target = self.out_lin(x_target)\n",
    "        return torch.softmax(x_target, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(L.LightningModule):\n",
    "    def __init__(self, model: TabTransformerEmbedder, target_table: str, lr: float) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.target_table = target_table\n",
    "        self.lr = lr\n",
    "        self.loss_module = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data: HeteroData):\n",
    "        out = self.model(data.collect(\"tf\"), data.collect(\"edge_index\", allow_empty=True))\n",
    "\n",
    "        target = data[self.target_table].y\n",
    "        loss = self.loss_module(out, target)\n",
    "        acc = (out.argmax(dim=-1) == target).type(torch.float).mean()\n",
    "        return loss, acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "        self.log(\"train_loss\", loss, batch_size=batch_size, prog_bar=True)\n",
    "        self.log(\"train_acc\", acc, batch_size=batch_size, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        _, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "\n",
    "        self.log(\"val_acc\", acc, batch_size=batch_size, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        _, acc = self.forward(batch)\n",
    "        batch_size = batch[self.target_table].y.shape[0]\n",
    "\n",
    "        self.log(\"test_acc\", acc, batch_size=batch_size, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CTUDataset(\"Chess\", data_dir=\"../datasets\", force_remake=False)\n",
    "\n",
    "data = dataset.build_hetero_data(device)\n",
    "\n",
    "n_total = data[dataset.defaults.target_table].y.shape[0]\n",
    "data = T.RandomNodeSplit(split=\"train_rest\", num_val=int(0.30 * n_total), num_test=0)(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.defaults.target\n",
    "\n",
    "model = Model(\n",
    "    target_table=target[0],\n",
    "    table_col_stats=data.collect(\"col_stats\"),\n",
    "    table_col_names_dict={k: tf.col_names_dict for k, tf in data.collect(\"tf\").items()},\n",
    "    edge_types=data.collect(\"edge_index\", allow_empty=True).keys(),\n",
    "    embed_dim=64,\n",
    "    num_embedder_layers=4,\n",
    "    num_embedder_heads=4,\n",
    "    num_transformer_heads=1,\n",
    "    embedder_attn_dropout=0.1,\n",
    "    out_dim=dataset.schema[target[0]].columns[target[1]].card,\n",
    ").to(device)\n",
    "lightning_model = LightningModel(model, dataset.defaults.target_table, lr=0.0001).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 5,\n",
    "    batch_size=1000,\n",
    "    input_nodes=(target[0], data[target[0]].train_mask),\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 5,\n",
    "    batch_size=1000,\n",
    "    input_nodes=(target[0], data[target[0]].val_mask),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=device.type,\n",
    "    devices=1,\n",
    "    deterministic=False,\n",
    "    max_epochs=100,\n",
    "    max_steps=-1,\n",
    ")\n",
    "\n",
    "trainer.fit(lightning_model, train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-db-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
