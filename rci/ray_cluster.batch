#!/bin/bash

#SBATCH --partition=cpu
#SBATCH --nodes=4
#SBATCH --cpus-per-task=32
#SBATCH --time=24:00:00

id=$1

python_script=$2

conda_env="deep-db-learning"

nodes=$(scontrol show hostnames "$SLURM_JOB_NODELIST")
nodes_array=($nodes)

echo ${nodes[*]}

node_1=${nodes_array[0]}
ip=$(srun --nodes=1 --ntasks=1 --gres=gpu:0 -w "$node_1" hostname --ip-address)

# if we detect a space character in the head node IP, we'll
# convert it to an ipv4 address. This step is optional.
if [[ "$ip" == *" "* ]]; then
  IFS=' ' read -ra ADDR <<< "$ip"
  if [[ ${#ADDR[0]} -gt 16 ]]; then
    ip=${ADDR[1]}
  else
    ip=${ADDR[0]}
  fi
  echo "IPV6 address detected. We split the IPV4 address as $ip"
fi

# set up head node
port=6379
ip_head=$ip:$port
export ip_head
echo "IP Head: $ip_head"

echo "cpus per task $SLURM_CPUS_PER_TASK"

# launch head node, leaving one core unused for the main python script
echo "STARTING HEAD at $node_1"
srun --job-name="ray-head" --nodes=1 --ntasks=1 --cpus-per-task=1 -w "$node_1" --pty bash \
    rci/conda_env.sh "$conda_env" \
    "ray start --head --num-cpus=1 --node-ip-address=$ip --port=$port --block" &
ray_head=$!
sleep 15

ray_workers=()

worker_num=$((SLURM_JOB_NUM_NODES - 1))
for ((i = 1; i <= worker_num; i++)); do
 node_i=${nodes_array[$i]}
 echo "STARTING WORKER $i at $node_i"
  srun --job-name="ray-worker" --nodes=1 --ntasks=1 -w "$node_i" --pty bash \
    rci/conda_env.sh "$conda_env" \
    "ray start --address=$ip_head --block --num-cpus=$SLURM_CPUS_PER_TASK" &
  ray_workers+=$!
  sleep 10
done

# export RAY_ADDRESS, so that ray can be initialised using ray.init(), without address
RAY_ADDRESS=$ip_head
RAY_ADDRESS_IP=$ip
export RAY_ADDRESS
export RAY_ADDRESS_IP

datasets=('Accidents' 'AdventureWorks2014' 'Airline' 'Atherosclerosis' 'AustralianFootball' 'Basketball_men'
    'Basketball_women' 'Biodegradability' 'Bupa' 'Carcinogenesis' 'ccs' 'CDESchools' 'Chess' 'CiteSeer'
    'classicmodels' 'ConsumerExpenditures' 'CORA' 'Countries' 'CraftBeer' 'Credit' 'cs' 'Dallas' 'DCG'
    'Dunur' 'Elti' 'employee' 'ErgastF1' 'Facebook' 'financial' 'FNHK' 'ftp' 'geneea' 'genes' 'GOSales'
    'Grants' 'Hepatitis_std' 'Hockey' 'imdb_ijs' 'KRK' 'lahman_2014' 'legalActs' 'Mesh' 'Mondial'
    'Mooney_Family' 'imdb_MovieLens' 'medical' 'MuskSmall' 'mutagenesis' 'nations' 'NBA' 'NCAA'
    'northwind' 'Pima' 'PremierLeague' 'PTC' 'PTE' 'PubMed_Diabetes' 'pubs' 'Pyrimidine' 'restbase'
    'sakila' 'SalesDB' 'Same_gen' 'SAP' 'SAT' 'Seznam' 'SFScores' 'Shakespeare' 'stats' 'Student_loan'
    'Toxicology' 'tpcc' 'tpcd' 'tpcds' 'tpch' 'trains' 'Triazine' 'university' 'UTube' 'UW_std' 'VisualGenome'
    'voc' 'Walmart' 'WebKP' 'world'
)

cls_datasets=('Accidents' 'Airline' 'Atherosclerosis' 'AustralianFootball' 
    'Basketball_women' 'Bupa' 'Carcinogenesis' 'Chess' 'CiteSeer' 'CORA'
    'CraftBeer' 'Credit' 'cs' 'Dallas' 'DCG' 'Dunur' 'Elti' 'ErgastF1' 
    'Facebook' 'financial' 'ftp' 'geneea' 'genes' 'Hepatitis_std' 'Hockey' 
    'imdb_ijs' 'KRK' 'legalActs' 'Mesh' 'Mondial' 'imdb_MovieLens' 'medical'
    'MuskSmall' 'mutagenesis' 'nations' 'NBA' 'NCAA' 'Pima' 'PremierLeague'
    'PTE' 'PubMed_Diabetes' 'Same_gen' 'SAP' 'SAT' 'Student_loan' 'Toxicology' 
    'tpcc' 'tpcd' 'tpcds' 'trains' 'university' 'UTube' 'UW_std' 'voc' 'WebKP' 'world'
)

reg_datasets=('AdventureWorks2014' 'Basketball_men' 'Biodegradability' 'ccs'
    'CDESchools' 'classicmodels' 'ConsumerExpenditures' 'Countries' 'employee'
    'FNHK' 'GOSales' 'Grants' 'lahman_2014' 'northwind' 'PTC' 'pubs' 'Pyrimidine'
    'restbase' 'sakila' 'SalesDB' 'Seznam' 'SFScores' 'stats' 'tpch' 'Triazine'
    'Walmart'
)

try_datasets=('Chess' 'CORA' 'mutagenesis')

run_pids=()
for dataset in "${cls_datasets[@]}"
do
    srun --output=./logs/${id}/${dataset}/run.log --nodes=1 --ntasks=1 --cpus-per-task=1 --gres=gpu:0 \
    python -u ${python_script} --ray_address=${ip_head} \
    --experiment=deep-db-experiments-pelesjak \
    --dataset=${dataset} --num_samples=8 --run_name=${id}_${dataset} &

    run_pids+=($!)

    sleep 5
done

for pid in ${run_pids[*]}; do
    wait $pid
done

# stop the ray cluster
for worker in "${ray_workers[@]}"
do
  kill $worker
done
kill $ray_head

wait

